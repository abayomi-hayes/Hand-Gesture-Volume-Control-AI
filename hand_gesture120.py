# -*- coding: utf-8 -*-
"""Hand gesture120.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfirEI2TE6sdwuWUNxOz0_i3lOhecYko
"""

import cv2
import mediapipe as mp
import time
import math

# Class creation for hand detection
class handDetector():
    def __init__(self, mode=False, maxHands=2, detectionCon=0.5,modelComplexity=1,trackCon=0.5):
        self.mode = mode
        self.maxHands = maxHands
        self.detectionCon = detectionCon
        self.modelComplex = modelComplexity
        self.trackCon = trackCon
        self.mpHands = mp.solutions.hands
        self.hands = self.mpHands.Hands(self.mode, self.maxHands,self.modelComplex,
                                        self.detectionCon, self.trackCon)
        self.mpDraw = mp.solutions.drawing_utils  # it gives small dots onhands total 20 landmark points

    def findHands(self,img,draw=True):
        # Send rgb image to hands
        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        self.results = self.hands.process(imgRGB) # process the frame
    #     print(results.multi_hand_landmarks)

        if self.results.multi_hand_landmarks:
            for handLms in self.results.multi_hand_landmarks:

                if draw:
                    #Draw dots and connect them
                    self.mpDraw.draw_landmarks(img,handLms,
                                                self.mpHands.HAND_CONNECTIONS)

        return img

    def findPosition(self,img, handNo=0, draw=True):
        """Lists the position/type of landmarks
        we give in the list and in the list ww have stored
        type and position of the landmarks.
        List has all the lm position"""

        lmlist = []

        # check wether any landmark was detected
        if self.results.multi_hand_landmarks:
            #Which hand are we talking about
            myHand = self.results.multi_hand_landmarks[handNo]
            # Get id number and landmark information
            for id, lm in enumerate(myHand.landmark):
                # id will give id of landmark in exact index number
                # height width and channel
                h,w,c = img.shape
                #find the position
                cx,cy = int(lm.x*w), int(lm.y*h) #center
                # print(id,cx,cy)
                lmlist.append([id,cx,cy])

                # Draw circle for 0th landmark
                if draw:
                    cv2.circle(img,(cx,cy), 15 , (255,0,255), cv2.FILLED)

        return lmlist

def main():
    #Frame rates
    pTime = 0
    cTime = 0
    cap = cv2.VideoCapture(0)
    detector = handDetector()

    while True:
        success,img = cap.read()
        img = detector.findHands(img)
        lmList = detector.findPosition(img)
        if len(lmList) != 0:
            print(lmList[4])

        cTime = time.time()
        fps = 1/(cTime-pTime)
        pTime = cTime

        cv2.putText(img,str(int(fps)),(10,70), cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)

        cv2.imshow("Video",img)
        if cv2.waitKey(1) == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()

import cv2
import time
import numpy as np
import HandTrackingModule as htm
import math
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

# Set webcam resolution

wCAm, hCam = 640, 480



# Initialize webcam and set resolution
cap = cv2.VideoCapture(0)
cap.set(3,wCAm)
cap.set(4,hCam)
pTime = 0

# Initialize the hand detector object
detector = htm.handDetector(detectionCon=0.7)


# Get the audio output device and volume control interface
devices = AudioUtilities.GetSpeakers()
interface = devices.Activate(
    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
volume = cast(interface, POINTER(IAudioEndpointVolume))

# volume.GetMute()
# volume.GetMasterVolumeLevel()
# Get the volume range
volRange = volume.GetVolumeRange()
# print(volRange)
# volume.SetMasterVolumeLevel(0, None)
minVol = volRange[0]
maxVol = volRange[1]
vol = 0
volBar = 400
volPer = 0

###############################



while True:
    # Read a frame from the webcam
    success, img = cap.read()
    # Find hands in the frame
    img = detector.findHands(img)
    lmList = detector.findPosition(img, draw=False)
    if len(lmList) != 0:

######## Steps For Advance #####################
        # Filter based on size
        # Find Distance between index and thumb
        # Convert Volume
        # Reduce Rsolution to make it smoother
        #  Check fingers up
        # if pinky is down set volume
        # Drawings
        # Frame Rate
#############################################


        # print(lmList[4], lmList[8])
# Get the positions of the thumb and index finger
        x1, y1 = lmList[4][1], lmList[4][2]
        x2, y2 = lmList[8][1], lmList[8][2]
        cx, cy = (x1 + x2) // 2, (y1 + y2) //2 # for center of line

# Draw circles at the thumb and index finger tips and a line between them
        cv2.circle(img, (x1,y1), 10,(255,0,255), cv2.FILLED)
        cv2.circle(img, (x2,y2), 10,(255,0,255), cv2.FILLED)
        cv2.line(img, (x1, y1), (x2,y2), (255,0,255),3)
        cv2.circle(img, (cx,cy), 10,(255,0,255), cv2.FILLED)

# Calculate the distance between the thumb and index finger (length of the line)
        length = math.hypot(x2-x1, y2-y1)
        # print(length)

        # Hand range 20 - 200
        # volume range -65 to 0
        # Convert the distance (length) to volume
        vol = np.interp(length,[20,200],[minVol, maxVol])
        volBar = np.interp(length,[20,200],[400, 150])
        volPer = np.interp(length,[20,200],[0, 100])

        print(int(length),vol)
        volume.SetMasterVolumeLevel(vol, None)

        if length < 20:
            cv2.circle(img, (cx,cy), 10,(0,255,0), cv2.FILLED)

 # Draw the volume bar and percentage on the frame
    cv2.rectangle(img, (50,150),(85,400),(0,255,0),3)
    cv2.rectangle(img, (50,int(volBar)),(85,400),(0,255,0),cv2.FILLED)
    cv2.putText(img, f'{int(volPer)}%', (40,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,250,0), 2)

# Calculate and display the frame rate
    cTime = time.time()
    fps = 1/(cTime-pTime)
    pTime = cTime

    cv2.putText(img, f'FPS: {int(fps)}', (40,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0), 2)

    cv2.imshow("Img", img)
    cv2.waitKey(1)